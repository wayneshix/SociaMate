channel_id,Date,user_id,user_name,content
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2024-11-07,17:56:26",jasonyan0454,jasonyan0454,"üìå If you have any questions or need support with Gemini or Google AI tools and resources, feel free to ask them on the Build with Google AI forum. It‚Äôs a great place to get expert advice. Don‚Äôt hesitate to share your questions there! Thank you! üöÄ"
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2024-11-07,17:56:33",jasonyan0454,jasonyan0454,
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2024-11-11,00:08:33",santhoshm_40155,santhoshm_40155,Kaggle #5dgai-announcements
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2024-11-15,20:17:29",tdinh2218,tdinh2218,Hi how do we get Google AI resource
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2024-11-16,02:12:14",jasonyan0454,jasonyan0454,We will provide more information later.
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2024-11-16,06:02:07",varshadewangan,varshadewangan,Kaggle #5dgai-announcements
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2024-11-16,06:02:28",varshadewangan,varshadewangan,Kaggle #5dgai-announcements
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2024-11-19,11:39:26",jasonyan0454,jasonyan0454,"üöÄ Upcoming Workshop with Google AI: Building with Gemini for the LLM Agents MOOC Hackathon üöÄ

Google AI will be hosting a special workshop for our hackathon, showcasing Gemini and how to leverage it in your projects. They‚Äôll be doing live demos and there‚Äôs a Q&A session where you can get direct advice from Google AI specialists.

üìÖ Date & Time: 11/26 3pm PT
üìç Where: Livestreamed on YouTube - Join us from anywhere!
 üîó RSVP & More Info: https://lu.ma/agents-hackathon-googleai

Don‚Äôt miss this chance to learn from the Google AI team and boost your hackathon project!"
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2024-11-19,11:39:37",jasonyan0454,jasonyan0454,
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2024-11-25,00:23:14",thewilsonglobal,thewilsonglobal,RISC Zero #üö®ÔΩúannouncements
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2024-11-26,09:11:25",jasonyan0454,jasonyan0454,"@everyone 
Join us for the Hackathon Workshop with Google AI, happening at 3 PM PT today (11/26). Don‚Äôt miss out on the opportunity to ask your questions and gain insights directly from Google AI specialists!
üîó Watch live here: https://www.youtube.com/watch?v=8lu0hCrfUXk
Set your reminders and see you there! ‚è∞"
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2024-11-26,15:10:03",tilman_91445,tilman_91445,"Oh no, she showed the outdated lmsys screenshot üòâ  https://x.com/emollick/status/1859698745291702341"
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2024-12-06,21:55:44",andigo0939,andigo0939,Kaggle #5dgai-announcements
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2024-12-08,03:09:52",guna_12,guna_12,<@879805514580656178>  hello
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2024-12-08,03:09:56",guna_12,guna_12,I have some questions
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2024-12-08,03:10:10",guna_12,guna_12,I've dm you
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2024-12-09,11:21:14",AG2 #announcements,AG2 #announcements,"@everyone ü§Ø You're Building WHAT with AG2?!

Every week we discover absolutely mind-blowing things being built with AG2 in production. Someone just told us they built the world‚Äôs first open-source software testing agent using AG2. Another team is using it to automate WhatsApp and email replies with AI Agents, enrich leads with deep insights, and personalize outreach at scale.

With 330k+ monthly downloads, we know there are more incredible stories out there. Now we want to hear YOURS.

Running AG2 in production? Share your story in our quick survey, and if selected, you'll join an exclusive group of production users who get:
* Private Discord channel with direct access to AG2's engineering team
* 1:1 technical consultation with our founders
* Early access & input to new features
* Limited edition AG2 merch as a thank you

üìù Join us: https://jc9pie8gn0f.typeform.com/ag2production 

First 50 qualified teams get priority access!

Know someone running AG2 in production? Tag them below! ü§ñ"
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2024-12-11,14:43:22",r5h_,r5h_,Perplexity #üì¢‚îÇevents
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2024-12-11,16:28:22",pranay_pasula,pranay_pasula,Thanks for sharing! I have a few papers using Autogen as a SotA baseline! Excited to check out AG2!
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2024-12-22,05:50:01",tangsong_87843,tangsong_87843,Ollama #announcements
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2024-12-22,05:51:10",tangsong_87843,tangsong_87843,Ollama #announcements
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2024-12-25,06:29:35",varshadewangan,varshadewangan,SWOC (Social Winter of Code) #announcements
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2024-12-25,14:35:54",mohammad_talaei,mohammad_talaei,SPAM
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2024-12-25,14:41:05",yash_goth_81987,yash_goth_81987,Reported
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2024-12-31,06:41:07",SWOC (Social Winter of Code) #announcements,SWOC (Social Winter of Code) #announcements,@everyone **Update for Project Admins** check your mails next steps and group link is shared
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-01-01,04:01:17",SWOC (Social Winter of Code) #announcements,SWOC (Social Winter of Code) #announcements,@everyone Update : Check In forms will be mailed post opening ceremony just fill that our team we start the check in
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-01-01,04:58:02",SWOC (Social Winter of Code) #announcements,SWOC (Social Winter of Code) #announcements,"@everyone 

Please check your email for the check-in form. You might have received it from either Devfolio Announcements or socialwinterofcode@gmail.com. Don‚Äôt forget to check your spam folder as well!"
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-01-02,05:00:42",varshadewangan,varshadewangan,SWOC (Social Winter of Code) #announcements
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-01-03,10:50:12",upendrayadav_61949,upendrayadav_61949,Hey
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-01-08,10:27:04",Ollama #announcements,Ollama #announcements,"Model page: 
https://ollama.com/library/phi4"
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-01-10,00:29:51",SWOC (Social Winter of Code) #announcements,SWOC (Social Winter of Code) #announcements,@everyone Take part in 1st SWOC Giveaway https://discord.com/channels/1118073956960841815/1299258383223754752/1327191660966187008
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-01-11,03:02:47",SWOC (Social Winter of Code) #announcements,SWOC (Social Winter of Code) #announcements,"@everyone

Check out another article wrote on top python projects not to be missed in 2025 

https://dev.to/jaysaadana/top-python-open-source-projects-not-to-be-missed-in-2025-3cli"
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-01-12,10:47:27",gagan.2492,gagan.2492,Mecha #üì£‚îÉannouncements
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-01-14,21:41:37",rolling.mean,rolling.mean,Yannic Kilcher #events
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-01-19,20:58:15",SWOC (Social Winter of Code) #announcements,SWOC (Social Winter of Code) #announcements,"@everyone üöÄ Hack The Flag Registrations Are Now Open!
Join the ultimate feature flagging challenge with a $1,000 Prize Pool!

üîó Register Now: https://www.hackquest.io/hackathons/HackTheFlag

Showcase your skills, build amazing projects with Flagsmith, and compete for exciting prizes! Don‚Äôt miss out‚Äîsign up today and bring your A-game!"
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-01-25,09:06:28",Yannic Kilcher #events,Yannic Kilcher #events,"@everyone @meetup 
**Paper Discussion 2025#04**

<t:1737831600:F> until <t:1737838800:t>, @Yannic Kilcher will present `DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models` in <#719652499740688404>.
https://discord.gg/eZZ9jjBu?event=1332758016050597889

If you'd like to present a paper, send a direct message to @zickzack  with a link to the paper and availability information.

**Paper:**
https://arxiv.org/abs/2402.03300

**Abstract:**
Mathematical reasoning poses a significant challenge for language models due to its complex and structured nature. In this paper, we introduce DeepSeekMath 7B, which continues pre-training DeepSeek-Coder-Base-v1.5 7B with 120B math-related tokens sourced from Common Crawl, together with natural language and code data. DeepSeekMath 7B has achieved an impressive score of 51.7% on the competition-level MATH benchmark without relying on external toolkits and voting techniques, approaching the performance level of Gemini-Ultra and GPT-4. Self-consistency over 64 samples from DeepSeekMath 7B achieves 60.9% on MATH. The mathematical reasoning capability of DeepSeekMath is attributed to two key factors: First, we harness the significant potential of publicly available web data through a meticulously engineered data selection pipeline. Second, we introduce Group Relative Policy Optimization (GRPO), a variant of Proximal Policy Optimization (PPO), that enhances mathematical reasoning abilities while concurrently optimizing the memory usage of PPO."
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-01-27,05:32:30",SWOC (Social Winter of Code) #announcements,SWOC (Social Winter of Code) #announcements,"**Join HackTheFlag, organized by SWOC, and showcase your skills in feature flag innovation with Flagsmith!** @everyone
üí∞ Prize Pool: $1,000‚Ä®üóì Date: 10th March - 24th March 2025 (Virtual Hackathon)
Build innovative solutions, compete globally, and win exciting prizes!
üëâ Register Now:¬†https://www.hackquest.io/hackathons/HackTheFlag
Don‚Äôt miss out‚Äîparticipate as an individual or a team! üöÄ"
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-01-28,04:42:44",shafi_5110,shafi_5110,aiXplain #announcements
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-01-28,21:41:50",charlybkk,charlybkk,"Would love to see a benchmark with DeepSeek, as it is the buzz word of the moment, but i doubt it would be on the top of the list..."
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-02-01,06:14:22",ashishpatel26,ashishpatel26,Learn AI Together #üß†„Éªwhatsai-new-content
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-02-02,06:45:26",Learn AI Together #üß†„Éªwhatsai-new-content,Learn AI Together #üß†„Éªwhatsai-new-content,"@everyone, new @WAI Videos !

Let's break the hype: Real Agents vs. Workflows: The Truth Behind AI 'Agents'

Learn more in the video: https://youtu.be/kQxr-uOxw2o"
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-02-03,17:52:50",AG2 #announcements,AG2 #announcements,"üéØ Calling all AG2 + Google Cloud wizards! Show us your magic at Google Cloud Next 2025

Building something epic? We're selecting innovative companies to spotlight at one of tech's biggest stages - Google Cloud Next in Las Vegas this April. If you're crafting breakthrough solutions using AG2 and Google Cloud together, this is your chance to share your stackcraft with the world.

Why present at Next '25:
- Demo your innovation to tens of thousands of fellow builders and decision makers
- Join an elite group of featured customers alongside industry pioneers
- Deep dive with Google Cloud engineers and technical leaders
- Help shape the future of enterprise AI implementation

‚ö°Ô∏è Submit your story with a quick survey: https://jc9pie8gn0f.typeform.com/to/lViEe9TF 
@everyone"
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-02-05,05:15:57",Learn AI Together #üß†„Éªwhatsai-new-content,Learn AI Together #üß†„Éªwhatsai-new-content,"@everyone, new @WAI Videos ! 

**The future of software development: LLM Developers**

Software engineers vs. ML engineers vs. prompt engineers vs. LLM developers... what's the difference?

Learn more in the video: https://youtu.be/UbLJuxSqEN0"
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-02-05,11:19:32",aiXplain #announcements,aiXplain #announcements,"@everyone  üì¢ üó£Ô∏è  Quick announcement : We just renamed our server to ""AI Agent Lab"" ... Join us to build AI agents and explore its power together.. üí™üèæ 

P.S.: Next developer office hour coming up soon

TOPIC: Ins and Outs of Agentic RAG with @pavalucas 

Check this out: https://www.linkedin.com/posts/aixplain_officehours-activity-7292904826105995264-hzp3?utm_source=share&utm_medium=member_desktop and RSVP üëáüèæ 

https://discord.gg/tXK4eNHP?event=1334221517621563554"
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-02-06,07:58:23",SWOC (Social Winter of Code) #announcements,SWOC (Social Winter of Code) #announcements,"@everyone 
Soon Project Submission On Devfolio Starts , stay tune for more details 

Note : This is an important step to get final certifications and scores in the end of program"
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-02-08,07:36:21",Yannic Kilcher #events,Yannic Kilcher #events,"@everyone @meetup 
**Paper Discussion 2025#06**

Saturday, local: <t:1739041200:F> - <t:1739048400:t>, @zickzack    will present `Safe and Efficient Off-Policy Reinforcement Learning` in <#719652499740688404>.
[Event](https://discord.com/events/714501525455634453/1337720997452845096)

If you'd like to present a paper, send a direct message to @zickzack  with a link to the paper and availability information.


**Paper:**
https://arxiv.org/abs/1606.02647v2

**Abstract:**
>       In this work, we take a fresh look at some old and new algorithms for off-policy, return-based reinforcement learning. Expressing these in a common form, we derive a novel algorithm, Retrace(Œª), with three desired properties: (1) it has low variance; (2) it safely uses samples collected from any behaviour policy, whatever its degree of ""off-policyness""; and (3) it is efficient as it makes the best use of samples collected from near on-policy behaviour policies. We analyze the contractive nature of the related operator under both off-policy policy evaluation and control settings and derive online sample-based algorithms. We believe this is the first return-based off-policy control algorithm converging a.s. to Q‚àó without the GLIE assumption (Greedy in the Limit with Infinite Exploration). As a corollary, we prove the convergence of Watkins' Q(Œª), which was an open problem since 1989. We illustrate the benefits of Retrace(Œª) on a standard suite of Atari 2600 games."
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-02-09,22:11:02",SWOC (Social Winter of Code) #announcements,SWOC (Social Winter of Code) #announcements,@everyone Take Part in this exclusive and season last giveaways https://discord.com/channels/1118073956960841815/1299258383223754752/1338384103199997954
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-02-11,11:35:11",Learn AI Together #üß†„Éªwhatsai-new-content,Learn AI Together #üß†„Éªwhatsai-new-content,"@everyone, new @WAI Videos !

**How LLMs Are Changing Every Job (And What You Can Do About It)**

Video 3/6 of the ""8-hour Generative AI Primer"" course by Towards AI.

Learn more in the video: https://youtu.be/1iHJGTlyDqc"
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-02-11,11:53:48",aiXplain #announcements,aiXplain #announcements,"@everyone REMINDER: Tomorrow we have our next chat on ""The Ins and Outs of Agentic RAG with @pavalucas "" Don't forget to RSVP: https://discord.gg/tXK4eNHP?event=1334221517621563554

 üóìÔ∏è Wednesday, 9 am PST
üìå  Dev-Lounge"
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-02-13,11:10:02",jvthunder,jvthunder,Report?
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-02-13,11:32:59",dr.spaceman,dr.spaceman,https://tenor.com/view/imbussinggg-gif-11260219515970408885
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-02-13,11:35:11",xvip,xvip,üòÇ
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-02-13,12:41:04",nomypython,nomypython,oh now we have spam attack
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-02-13,12:41:05",nomypython,nomypython,üò≠
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-02-13,12:41:16",discogerm,discogerm,Aw hell naw
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-02-13,12:41:26",drako8309,drako8309,>:v
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-02-13,12:41:35",dr.spaceman,dr.spaceman,https://tenor.com/view/ithaqua-idv-cokey-cola-social-security-number-mothers-maiden-name-gif-3545171079100481028
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-02-13,13:28:31",Ollama #announcements,Ollama #announcements,"# Ollama 0.5.9

- [DeepScaleR](https://ollama.com/library/deepscaler): A fine-tuned version of Deepseek-R1-Distilled-Qwen-1.5B that surpasses the performance of OpenAI‚Äôs o1-preview with just 1.5B parameters on popular math evaluations.
- [OpenThinker](https://ollama.com/library/openthinker): A fully open-source family of reasoning models built using a dataset derived by distilling DeepSeek-R1.

## What's Changed
* Fixed `llama runner process has terminated` that would occur on Windows due to permissions issues
* Ollama will now use AVX-512 instructions where available for additional CPU acceleration
* NVIDIA and AMD GPUs can now be used with CPUs without AVX instructions
* Ollama will now use AVX2 instructions with NVIDIA and AMD GPUs
* New `ollama-darwin.tgz` package for macOS that replaces the previous `ollama-darwin` standalone binary.
* Fixed indexing error that would occur when downloading a model with `ollama run` or `ollama pull`
* Fixes cases where download progress would reverse

**Full Changelog**: https://github.com/ollama/ollama/releases/tag/v0.5.9

@everyone"
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-02-14,16:58:57",aiXplain #announcements,aiXplain #announcements,"üíò Roses are red, Violets are blue, If your AI isn‚Äôt working, aiXplain is for you! üíò

Valentine‚Äôs Day is all about finding the perfect match‚Äîand not just for people, but for AI models and agents too.

Tired of being stuck in a toxic relationship with underperforming AI? üíî
üíÄ Your LLM takes forever to respond?
üí∏ Burning credits faster than a bad date spends money?
üò© Your AI agent is ghosting you instead of executing tasks?

It‚Äôs time to upgrade your relationship status with aiXplain‚Äôs Agentic Framework.
üíë Find the best LLM (DeepSeek or Llamas on Groq, Together AI, SambaNova‚Äîyou name it!)
üíå Team up agents to get things done without unnecessary drama
üíç Optimize performance with benchmarking, so you know exactly what you‚Äôre committing to

Because let‚Äôs be real‚Äînothing says love like low-latency inference, cost-efficient API calls, and AI agents that actually get the job done. ‚ù§Ô∏è

Ready to swipe right on better AI? Check out the docs here and get started: https://docs.aixplain.com/"
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-02-15,04:03:14",Yannic Kilcher #events,Yannic Kilcher #events,"@everyone @meetup 
**Paper Discussion 2025#07**

Saturday, local: <t:1739646000:F> - <t:1739653200:t>, @0x000ff4   will present `Approximation Theory and Approximation Practice, Extended Edition (Chap. 1-3)` in <#1337720641528401930>.
[Event](https://discord.com/events/714501525455634453/1338226457079713932)

If you'd like to present a paper, send a direct message to @zickzack  with a link to the paper and availability information.


**Paper:**
https://epubs.siam.org/doi/10.1137/1.9781611975949

**Abstract:**
>  This is a textbook on classical polynomial and rational approximation theory for the twenty-first century. Aimed at advanced undergraduates and graduate students across all of applied mathematics, it uses MATLAB to teach the field's most important ideas and results.
> 
> Approximation Theory and Approximation Practice, Extended Edition differs fundamentally from other works on approximation theory in a number of ways: its emphasis is on topics close to numerical algorithms; concepts are illustrated with Chebfun; and each chapter is a PUBLISHable MATLAB M-file, available online.
> 
> The book centers on theorems and methods for analytic functions, which appear so often in applications, rather than on functions at the edge of discontinuity with their seductive theoretical challenges. Original sources are cited rather than textbooks, and each item in the bibliography is accompanied by an editorial comment. In addition, each chapter has a collection of exercises, which span a wide range from mathematical theory to Chebfun-based numerical experimentation.
> 
> This textbook is appropriate for advanced undergraduate or graduate students who have an understanding of numerical analysis and complex analysis. It is also appropriate for seasoned mathematicians who use MATLAB.
Note: if you have ever used chebfun in MATLAB: this is the book written by the authors"
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-02-16,06:47:35",gaganadev,gaganadev,Why do i not have access to the channel? Is there something I have to do first?
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-02-16,06:48:39",gaganadev,gaganadev,"How do we register for the event and also, in which time zone is the event happening?"
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-02-18,01:21:59",SWOC (Social Winter of Code) #announcements,SWOC (Social Winter of Code) #announcements,@everyone Thanks for comming at the Daytona Meetup in Dehradun soon coming in your city
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-02-18,01:21:59",SWOC (Social Winter of Code) #announcements,SWOC (Social Winter of Code) #announcements,https://www.linkedin.com/posts/jaysaadana_daytona-meetup-opensource-activity-7297545242386305024-z-uW?utm_source=share&utm_medium=member_desktop&rcm=ACoAABbucb4BANtex2g69ijEKfGd-l9N5YXA6dI
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-02-20,08:04:41",SWOC (Social Winter of Code) #announcements,SWOC (Social Winter of Code) #announcements,"@everyone 

If you are in open source and looking forward to explore web3 read the lastest blog on dev to how it will help you to start https://dev.to/jaysaadana/open-source-in-web3-and-decentralized-applications-for-2025-a-new-era-of-innovation-mo8"
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-02-23,22:12:22",SWOC (Social Winter of Code) #announcements,SWOC (Social Winter of Code) #announcements,"@everyone
If you are in open source and working in frontend this blog is for you learn about streamline release from top companies like flagsmith,garfana etc

https://dev.to/jaysaadana/open-source-tools-for-streamlining-release-management-2bcf"
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-02-25,02:28:40",SWOC (Social Winter of Code) #announcements,SWOC (Social Winter of Code) #announcements,"üåê BIG Announcement from Endless Domains! üöÄ

Hey @everyone 

We‚Äôre building something MASSIVE at Endless Domains‚Äîa revolution in digital identity! Our mission? To make Web3 domains the new standard for individuals and businesses, creating the largest decentralized domain marketplace where you can seamlessly buy, sell, and utilize Web3 domains across blockchain ecosystems.

üî• Why Join Us?
‚úÖ Be part of an early Web3 movement
‚úÖ Connect with developers, domain enthusiasts & blockchain innovators
‚úÖ Get exclusive updates, AMAs, and early opportunities

The future of Web3 domains is being built right now‚Äîand we want YOU to be a part of it!

üöÄ Ready to shape the future?
Join our Discord today: üëâ https://discord.gg/Fs6qCDxpD6

Let‚Äôs build the next era of decentralized identity‚Äîtogether! üåêüí°"
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-02-27,06:13:11",Mecha #üì£‚îÉannouncements,Mecha #üì£‚îÉannouncements,"Hey @everyone, we are having our first live event on 8th March for major announcements and updates üöÄ about the Mecha Comet. The event will be live streamed on Youtube, you can use this link to get notified -   https://mecha.so/events/the-comet-blazes-march-2025. Can't wait to share everything we have been up to!

Also this will be a deep technical dive and not just announcements, we thought why should we have all the fun üòÑ"
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-03-01,09:59:17",Yannic Kilcher #events,Yannic Kilcher #events,"@everyone @meetup 
**Paper Discussion 2025#09**

Saturday, local: <t:1740855600:F> - <t:1740862800:t>, @.wavefunction  will present `Large Concept Models: Language Modeling in a Sentence Representation Space` in <#1337720641528401930>.
[Event](https://discord.com/events/714501525455634453/1344717219619278888)

If you'd like to present a paper, send a direct message to @zickzack  with a link to the paper and availability information.

**Paper:**
https://arxiv.org/abs/2412.08821

**Abstract:**
>  LLMs have revolutionized the field of artificial intelligence and have emerged as the de-facto tool for many tasks. The current established technology of LLMs is to process input and generate output at the token level. This is in sharp contrast to humans who operate at multiple levels of abstraction, well beyond single words, to analyze information and to generate creative content. In this paper, we present an attempt at an architecture which operates on an explicit higher-level semantic representation, which we name a concept. Concepts are language- and modality-agnostic and represent a higher level idea or action in a flow. Hence, we build a ""Large Concept Model"". In this study, as proof of feasibility, we assume that a concept corresponds to a sentence, and use an existing sentence embedding space, SONAR, which supports up to 200 languages in both text and speech modalities.
> The Large Concept Model is trained to perform autoregressive sentence prediction in an embedding space. We explore multiple approaches, namely MSE regression, variants of diffusion-based generation, and models operating in a quantized SONAR space. These explorations are performed using 1.6B parameter models and training data in the order of 1.3T tokens. We then scale one architecture to a model size of 7B parameters and training data of about 2.7T tokens."
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-03-03,04:51:57",.vasudeva,.vasudeva,cmon man
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-03-03,04:52:29",.vasudeva,.vasudeva,"cmon man, pls remove it"
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-03-03,04:55:11",.abdul.rahman.,.abdul.rahman.,most probably his account got hacked (pretty common for discord accounts to get hacked and sending weird links like this)
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-03-03,06:11:45",ma7dev,ma7dev,mods
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-03-03,06:41:57",nomypython,nomypython,Someon ban this peice of shit
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-03-03,06:42:00",nomypython,nomypython,dumb fuck
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-03-03,06:42:03",account_deactivated,account_deactivated,MODS
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-03-03,06:42:09",account_deactivated,account_deactivated,<@1226916012516184139>
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-03-03,06:42:16",account_deactivated,account_deactivated,<@&1301791197362262066>
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-03-03,06:42:20",account_deactivated,account_deactivated,<@&1301791197362262066>
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-03-03,06:43:13",account_deactivated,account_deactivated,My dear sleeping beauties please wake up and ban
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-03-03,06:49:09",thomasb0471,thomasb0471,Done in the lambda channel- I can‚Äôt do it in others‚Äô üò¶
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-03-03,06:53:42",omarwhite,omarwhite,Well just ignore and block him
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-03-03,07:05:34",Deleted User,Deleted User,I‚Äôm really sorry guys! I‚Äôve no clue what the fuck these links are or how they are appearing ! I apologise for the inconvenience caused
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-03-03,09:12:29",mweihenh,mweihenh,someone removes him pls
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-03-03,09:13:20",punkbaristawitch,punkbaristawitch,Change your passwords and work  on updating your security measures
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-03-03,09:14:31",infectedcrotch,infectedcrotch,is this discord dead? any mods?
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-03-03,09:15:35",infectedcrotch,infectedcrotch,im out lol ‚òÆÔ∏è
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-03-03,09:16:27",Deleted User,Deleted User,Deleting my account. Sorry about this guys
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-03-03,09:16:41",.abdul.rahman.,.abdul.rahman.,yea create a new one
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-03-03,09:17:02",.abdul.rahman.,.abdul.rahman.,or just change your password
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-03-03,09:17:04",.abdul.rahman.,.abdul.rahman.,that works too
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-03-04,15:06:12",inna_75497,inna_75497,<@1333779292995321886>
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-03-08,10:45:58",Yannic Kilcher #events,Yannic Kilcher #events,"@everyone @meetup 
**Paper Discussion 2025#10**

Saturday, local: <t:1741460400:F> - <t:1741467600:t>, @.wavefunction  will present `Discrete Diffusion Modeling by Estimating the Ratios of the Data Distribution` in <#1337720641528401930>.
[Event](https://discord.com/events/714501525455634453/1347664003069116426)

If you'd like to present a paper, send a direct message to @zickzack  with a link to the paper and availability information.

**Paper:**
https://arxiv.org/abs/2310.16834

**Abstract:**
>       Despite their groundbreaking performance for many generative modeling tasks, diffusion models have fallen short on discrete data domains such as natural language. Crucially, standard diffusion models rely on the well-established theory of score matching, but efforts to generalize this to discrete structures have not yielded the same empirical gains. In this work, we bridge this gap by proposing score entropy, a novel loss that naturally extends score matching to discrete spaces, integrates seamlessly to build discrete diffusion models, and significantly boosts performance. Experimentally, we test our Score Entropy Discrete Diffusion models (SEDD) on standard language modeling tasks. For comparable model sizes, SEDD beats existing language diffusion paradigms (reducing perplexity by 25-75\%) and is competitive with autoregressive models, in particular outperforming GPT-2. Furthermore, compared to autoregressive mdoels, SEDD generates faithful text without requiring distribution annealing techniques like temperature scaling (around 6-8√ó better generative perplexity than un-annealed GPT-2), can trade compute and quality (similar quality with 32√ó fewer network evaluations), and enables controllable infilling (matching nucleus sampling quality while enabling other strategies besides left to right prompting)."
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-03-15,11:50:29",Yannic Kilcher #events,Yannic Kilcher #events,"@everyone @meetup 
**Paper Discussion 2025#11**

Saturday, local: <t:1742065200:F> - <t:1742072400:t>, @0x000ff4   will present `Approximation Theory and Approximation Practice, Extended Edition (Chap. 4-6)` in <#1337720641528401930>.
[Event](https://discord.com/events/714501525455634453/1350380138650669086)

If you'd like to present a paper, send a direct message to @zickzack  with a link to the paper and availability information.


**Paper:**
https://epubs.siam.org/doi/10.1137/1.9781611975949

**Abstract:**
>  This is a textbook on classical polynomial and rational approximation theory for the twenty-first century. Aimed at advanced undergraduates and graduate students across all of applied mathematics, it uses MATLAB to teach the field's most important ideas and results.
> 
> Approximation Theory and Approximation Practice, Extended Edition differs fundamentally from other works on approximation theory in a number of ways: its emphasis is on topics close to numerical algorithms; concepts are illustrated with Chebfun; and each chapter is a PUBLISHable MATLAB M-file, available online.
> 
> The book centers on theorems and methods for analytic functions, which appear so often in applications, rather than on functions at the edge of discontinuity with their seductive theoretical challenges. Original sources are cited rather than textbooks, and each item in the bibliography is accompanied by an editorial comment. In addition, each chapter has a collection of exercises, which span a wide range from mathematical theory to Chebfun-based numerical experimentation.
> 
> This textbook is appropriate for advanced undergraduate or graduate students who have an understanding of numerical analysis and complex analysis. It is also appropriate for seasoned mathematicians who use MATLAB.
Note: if you have ever used chebfun in MATLAB: this is the book written by the authors"
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-03-15,13:07:10",aseembits93,aseembits93,"Hi! following you since the attention is all you need video, could you tell me more about the location of this event? I recently joined this server"
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-03-16,00:57:22",SWOC (Social Winter of Code) #announcements,SWOC (Social Winter of Code) #announcements,[Original Message Deleted]
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-03-16,00:57:22",SWOC (Social Winter of Code) #announcements,SWOC (Social Winter of Code) #announcements,"Hi @everyone

Those who haven‚Äôt received the certificates kindly fill below form as we will be checking with Give My Certificate to issue at the earliest"
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-03-16,08:29:10",Learn AI Together #üß†„Éªwhatsai-new-content,Learn AI Together #üß†„Éªwhatsai-new-content,"@everyone, new @WAI Videos !

**We are diving into Reinforcement Fine-Tuning (RFT) üëÄ**

What it is, how it works, when to use it and more...

**Let's demystify supervised fine-tuning vs. reinforcement fine-tuning.**

Both essentially have their use that we can discuss in one line:
‚Ä¢ Supervised fine-tuning teaches new things the model does not know yet, like a new language, which is powerful for small and less ‚Äúintelligent‚Äù models.
‚Ä¢ Reinforcement fine-tuning orients the current model to what we really want it to say. It basically ‚Äúaligns‚Äù the model to our needs, but we need an already powerful model. This is why reasoning models are a perfect fit.

Learn more in the video (and leave a comment to support my work there! ‚ù§Ô∏è): https://youtu.be/i40tCb7bkmg

p.s. the video is sponsored by Nvidia, which is a nice opportunity to mention that I will be at GTC from tomorrow (17th to 21st) is you'd like to meet and chat!"
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-03-17,01:15:55",SWOC (Social Winter of Code) #announcements,SWOC (Social Winter of Code) #announcements,https://docs.google.com/spreadsheets/d/1VrV305QK5hoBODHTThjo9-AqvrcljS0XaHI-m95cn-I/edit?usp=sharing
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-03-17,01:15:55",SWOC (Social Winter of Code) #announcements,SWOC (Social Winter of Code) #announcements,Hi @everyone
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-03-17,01:15:55",SWOC (Social Winter of Code) #announcements,SWOC (Social Winter of Code) #announcements,Certificates has been issued
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-03-17,01:15:56",SWOC (Social Winter of Code) #announcements,SWOC (Social Winter of Code) #announcements,in case you havent fot the mail you can serch from below excel file
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-03-17,01:16:48",SWOC (Social Winter of Code) #announcements,SWOC (Social Winter of Code) #announcements,Search using your name in the excel sheet as filled the form we havent added any mail id entries in the excel due to security reasons @everyone
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-03-19,08:16:36",Learn AI Together #üß†„Éªwhatsai-new-content,Learn AI Together #üß†„Éªwhatsai-new-content,"@everyone new video!

**DeepSeek's FlashMLA Explained!**

DeepSeek‚Äôs Game-Changer for LLM Efficiency, cutting KV Cache Memory to 6.7%! (yes, to 6.7% of traditional methods, not by 6.7%!!). ü§Ø

Learn more in the video: https://youtu.be/PTNW3SLP8W8"
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-03-19,23:32:17",SWOC (Social Winter of Code) #announcements,SWOC (Social Winter of Code) #announcements,Glad to get nominated in CMX Awards looking for support and votes
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-03-22,10:25:25",Yannic Kilcher #events,Yannic Kilcher #events,"@everyone @meetup 
**Paper Discussion 2025#12**

Saturday, local: <t:1742670000:F> - <t:1742677200:t>, @zickzack    will present `Optimization over Polynomials (Semialgebraic Optimization)` in <#1337720641528401930>.
[Event](https://discord.com/events/714501525455634453/1352715869943234570))

If you'd like to present a paper, send a direct message to @zickzack  with a link to the paper and availability information.


**Paper:**
- https://www.cambridge.org/core/books/an-introduction-to-polynomial-and-semialgebraic-optimization/5A7C6F7E54E28CE72BA7A7F84D0858ED
- https://www.worldscientific.com/worldscibooks/10.1142/p665#t=aboutBook

**Abstract:**
>  We have heard a lot about polynomial approximation, let's talk about optimizing polynomials:
> Semialgebraic Optimization (SOA) allows for the optimization of arbitary polynomials with arbitrary polynomial constraints, meaning we can solve challenging optimization problems to global optimality by simply approximating the constraints and objectives with polynomials."
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-03-24,01:06:29",lihua0817,lihua0817,hello
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-03-24,10:47:25",aiXplain #announcements,aiXplain #announcements,"@everyone üöÄ Just dropped: RFP Streamliner Agent built with aiXplain‚Äôs Agentic Framework!

We get asked all the time‚Äî‚ÄúWhat are real companies building agents for?‚Äù

One big one: automating the painful RFP process.

Our new multi-agent system handles it end-to-end:
üîé Detects and matches RFPs relevant to your business
‚úçÔ∏è Drafts responses using past proposals + internal data (via our Index + RAG)
üé® Formats everything and even generates visuals
üß† You stay in the loop to review and refine

No more hours lost on every proposal. This saves serious time and helps teams catch more opportunities.

üëÄ Want a closer look? Ping us‚Äîhappy to walk you through how it works or help you build something similar.

SIgn up here --> https://platform.aixplain.com/register"
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-03-28,09:41:51",Learn AI Together #üß†„Éªwhatsai-new-content,Learn AI Together #üß†„Éªwhatsai-new-content,"@everyone new video!

**How Open-Sora 2.0 Built Sora-Level Video AI for $200K (Full Breakdown)**

Learn more in the video: https://youtu.be/gMdvyGVICfA"
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-03-28,22:14:08",abkfettuccine,abkfettuccine,"Another scammer
Bro people are building and grinding here
Aint no time for that bs
Wrong discord"
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-03-28,22:35:06",akash_dutta,akash_dutta,"<@456226577798135808>  please get lost, dont like this kind of marketing people."
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-03-28,22:53:42",dungclaire,dungclaire,pretty sure that‚Äôs not marketing üôÇ could we summon the admin to kick it out?
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-03-29,10:51:06",Yannic Kilcher #events,Yannic Kilcher #events,"@everyone @meetup 
**Paper Discussion 2025#13**

<t:1743274800:F> until <t:1743282000:t>, @Yannic Kilcher will present `On the Biology of a Large Language Model` in https://discord.com/channels/714501525455634453/1337720641528401930.

Event:
https://discord.gg/brkRa9Fz?event=1355593496806948874

If you'd like to present a paper, send a direct message to @zickzack  with a link to the paper and availability information.

**Paper:**
https://transformer-circuits.pub/2025/attribution-graphs/biology.html

**Abstract:**
Large language models display impressive capabilities. However, for the most part, the mechanisms by which they do so are unknown. The black-box nature of models is increasingly unsatisfactory as they advance in intelligence and are deployed in a growing number of applications. Our goal is to reverse engineer how these models work on the inside, so we may better understand them and assess their fitness for purpose.

The challenges we face in understanding language models resemble those faced by biologists. Living organisms are complex systems which have been sculpted by billions of years of evolution. While the basic principles of evolution are straightforward, the biological mechanisms it produces are spectacularly intricate. Likewise, while language models are generated by simple, human-designed training algorithms, the mechanisms born of these algorithms appear to be quite complex."
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-03-29,11:36:19",arjunraghunandanan,arjunraghunandanan,"Hi,
I have not been active on this group for a while now and haven't joined any of these things. I scrolled a bit and saw this happens weekly but I am not sure what these 'Paper Discussion sessions' include. Interested in just listening. Are we able to join and simply listen to discussion? 
Thanks."
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-03-30,16:40:36",knightofthebats,knightofthebats,I am interested to get an answer to this as well
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-03-30,16:48:16",arjunraghunandanan,arjunraghunandanan,"Follow up. I later noticed that the event is not part of this discord and its from another discord channel by Yannic Kilcher (YT)  being shared into here. Anyways, I joined it. Attended yesterdays session (just listening mainly ) there was  ~100 people listening. Even though the hours  is not suitable for my IST time zone, since its a Sat-Sun period, its easy to listen in over night. It was useful and I'm considering  joining in weekly."
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-03-31,09:30:06",SWOC (Social Winter of Code) #announcements,SWOC (Social Winter of Code) #announcements,"Hi @everyone 

To all Top 40 
Here is the XYZ Code that you can redeem 

Use HACKOV825 in the checkout and select domain for 1 year 

Note : This is valid for those contributors who have are in top 40 as there mails are linked with the code 

(Use mail ids as used at time of registrations in SWOC)"
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-03-31,10:10:00",Learn AI Together #üß†„Éªwhatsai-new-content,Learn AI Together #üß†„Éªwhatsai-new-content,"@everyone new video again! üòÑ

A shift from the usual deep dives. Going back to basics with: 

**The BIGGEST Differences Between Jupyter and Colab You Need to Know!**

It is a (very useful) introduction to Colab and Jupyter for beginners that we used in our new Python course, which is now live on Towards AI Acadamy. üôÇ

Learn more in the video: https://youtu.be/rkg9qIh6_0c"
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-03-31,11:28:15",unnoticible_99,unnoticible_99,"Hey 
Have the paper discussions been recorded ?"
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-04-04,13:56:55",Yannic Kilcher #events,Yannic Kilcher #events,"@everyone @meetup 
**Paper Discussion 2025#14**

Saturday, local: <t:1743876000:F> - <t:1743883200:t>, @culpritgene     will present `Emergence of Hidden Capabilities: Exploring Learning Dynamics in Concept Space` in <#1337720641528401930>.
[Event](https://discord.com/events/714501525455634453/1357817079839068505)

If you'd like to present a paper, send a direct message to @zickzack  with a link to the paper and availability information.

**Paper:**
https://openreview.net/forum?id=owuEcT6BTl
https://arxiv.org/abs/2502.01954
https://arxiv.org/abs/2405.15943

**Abstract:**
> Modern generative models demonstrate impressive capabilities, likely stemming from an ability to identify and manipulate abstract concepts underlying their training data. However, fundamental questions remain: what determines the concepts a model learns, the order in which it learns them, and its ability to manipulate those concepts? To address these questions, we propose analyzing a model‚Äôs learning dynamics via a framework we call the concept space, where each axis represents an independent concept underlying the data generating process. By characterizing learning dynamics in this space, we identify how the speed at which a concept is learned, and hence the order of concept learning, is controlled by properties of the data we term concept signal. Further, we observe moments of sudden turns in the direction of a model‚Äôs learning dynamics in concept space. Surprisingly, these points precisely correspond to the emergence of hidden capabilities, i.e., where latent interventions show the model possesses the capability to manipulate a concept, but these capabilities cannot yet be elicited via naive input prompting. [...]"
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-04-07,11:32:50",aiXplain #announcements,aiXplain #announcements,@everyone Llama 4 is out... out and about on aiXplain's dashboard... Sign up fast to experience what creative agents you can build with this powerful Llama 4 family.. Here's a quick video showing how you can access those models on aiXplain's dashboard.. Super eager to find out what you guys build.. Don't be shy from sharing what you build.. ‚òÆÔ∏è
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-04-08,07:17:59",Learn AI Together #üß†„Éªwhatsai-new-content,Learn AI Together #üß†„Éªwhatsai-new-content,"Morning @everyone... Today, coming straight from GTC 2025... a new @WAI Videos !

Here‚Äôs everything you need to know about the ‚Äúcoolest‚Äù event of GTC: Jensen‚Äôs Quantum panel with 14 leaders in the field...

**What 14 Top CEOs Revealed About the Future of Quantum (GTC 2025)**

Learn more in the video: https://youtu.be/oWKkHPEnnTk"
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-04-12,06:21:16",Yannic Kilcher #events,Yannic Kilcher #events,"@everyone @meetup 
**Paper Discussion 2025#15**

<t:1744480800:F> until <t:1744488000:t>, @Yannic Kilcher will present `d1: Scaling Reasoning in Diffusion Large Language Models via Reinforcement Learning` in https://discord.com/channels/714501525455634453/1337720641528401930.

Event:
https://discord.gg/ec2FXBFA?event=1360604881945366548

If you'd like to present a paper, send a direct message to @zickzack  with a link to the paper and availability information.

**Paper:**
https://dllm-reasoning.github.io/

**Abstract:**
Recent large language models (LLMs) have demonstrated strong reasoning capabilities that benefit from online reinforcement learning (RL). These capabilities have primarily been demonstrated within the left-to-right autoregressive (AR) generation paradigm. In contrast, non-autoregressive paradigms based on diffusion generate text in a coarse-to-fine manner. Although recent diffusion-based large language models (dLLMs) have achieved competitive language modeling performance compared to their AR counterparts, it remains unclear if dLLMs can also leverage recent advances in LLM reasoning.

To this end, we propose d1, a framework to adapt pre-trained masked dLLMs into reasoning models via a combination of supervised finetuning (SFT) and RL. Specifically, we develop and extend techniques to improve reasoning in pretrained dLLMs: (a) we utilize a masked SFT technique to distill knowledge and instill self-improvement behavior directly from existing datasets, and (b) we introduce a novel critic-free, policy-gradient based RL algorithm called diffu-GRPO."
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-04-13,06:51:26",Learn AI Together #üß†„Éªwhatsai-new-content,Learn AI Together #üß†„Éªwhatsai-new-content,"@everyone A new video from our Python course!

**AI for coding - Towards AI's Python Primer for Generative AI**

Learn more in the video: https://youtu.be/-50847s1ScU"
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-04-18,14:11:37",aiXplain #announcements,aiXplain #announcements,"@everyone So last week, we saw Llama 4, and just a few days back we have new OpenAI GPT4.1 family release which of course we onboarded on aiXplain's marketplace.... What are these models capable of ? 

""These models deliver improved efficiency and reasoning at multiple scales, supporting everything from lightweight tasks to complex agent-driven workflows.""

On aiXplain, you can:
‚úÖ Compare GPT‚Äë4.1 models against SOTA LLMs
‚úÖ Deploy instantly via unified API or build agents with no code
‚úÖ Benchmark performance and cost trade-offs tailored to your use case

Has anyone here used this family of models? What's your take?"
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-04-21,17:13:47",Learn AI Together #üß†„Éªwhatsai-new-content,Learn AI Together #üß†„Éªwhatsai-new-content,"@everyone New video from our Python course: 

**CS Fundamentals Concepts ‚Äî Our NEW One‚ÄëStop Starter Class**

Whether you're brand new to coding or need a quick refresher, this video breaks down core CS concepts and Python fundamentals in a way that actually makes sense.

Watch the video: https://youtu.be/_uRb5wlFhyw"
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-04-26,09:13:13",Yannic Kilcher #events,Yannic Kilcher #events,"@everyone @meetup 
**Paper Discussion 2025#17**

Saturday, local: <t:1745690400:F> - <t:1745697600:t>, @sacco215   will present `Oniris` in <#1337720641528401930>.
[Event](https://discord.com/events/714501525455634453/1364295499187748886)

If you'd like to present a paper, send a direct message to @zickzack  with a link to the paper and availability information.

**Paper:**
https://github.com/Francesco215/autoregressive_diffusion/
https://x.com/FrancescoSacco1/status/1914671486666735892

**Abstract:**
> World modelling hinges on the ability to accurately predict the next frame in a sequence, however it is a task fundamentally more complex than next-token prediction due to the high-dimensional and continuous nature of video data. To address this, we formalize next-frame prediction as a conditional reverse diffusion process, allowing us to iteratively refine each frame based on all previous ones. However, training such models efficiently is non-trivial. Most prior approaches sacrifice either generality or sample efficiency, often resorting to fixed-length generation, or shallow context usage.
> In Oniris, we introduce a new training strategy that preserves causality while dramatically improving sample efficiency by combining block-sparse attention and 3D causal convolutions. Additionally, our inference process is fast and scalable, leveraging autoregressive caching mechanisms similar to language models. Together, these innovations enable Oniris to perform efficient, high-quality video generation and world modelling across long sequences, laying the groundwork for a new generation of diffusion-based video models."
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-04-26,14:27:09",mmsaki,mmsaki,Looks like event was private?
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-04-28,14:53:01",Ollama #announcements,Ollama #announcements,"Qwen 3 is now available on Ollama! 

**Default (8B) **
ollama run qwen3

**0.6B parameter model**
ollama run qwen3:0.6b

**1.7B parameter model**
ollama run qwen3:1.7b

**4B parameter model**
ollama run qwen3:4b

**8B parameter model**
ollama run qwen3:8b

**14B parameter model**
ollama run qwen3:14b

**32B parameter model**
ollama run qwen3:32b

**30B mixture-of-experts model with 3B active parameters**
ollama run qwen3:30b-a3b

**235B mixture-of-experts model with 22B active parameters**
ollama run qwen3:235b-a22b"
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-05-02,04:56:58",domazine,domazine,<@1328962270859890798> how exactly can we attend these paper reading discussions and events that you post about
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-05-03,09:20:26",Yannic Kilcher #events,Yannic Kilcher #events,"@everyone @meetup 
**Paper Discussion 2025#18**

Saturday, local: <t:1746295200:F> - <t:1746302400:t>, @.wavefunction   will present `Muon` in <#1337720641528401930>.
[Event](https://discord.com/events/714501525455634453/1367872855077032055)

If you'd like to present a paper, send a direct message to @zickzack  with a link to the paper and availability information.

**Paper:**
https://kellerjordan.github.io/posts/muon/
https://arxiv.org/abs/2409.20325

**Abstract:**
> Deep learning optimizers are often motivated through a mix of convex and approximate second-order theory. We select three such methods -- Adam, Shampoo and Prodigy -- and argue that each method can instead be understood as a squarely first-order method without convexity assumptions. In fact, after switching off exponential moving averages, each method is equivalent to steepest descent under a particular norm. By generalizing this observation, we chart a new design space for training algorithms. Different operator norms should be assigned to different tensors based on the role that the tensor plays within the network. For example, while linear and embedding layers may have the same weight space of Rm√ón, these layers play different roles and should be assigned different norms. We hope that this idea of carefully metrizing the neural architecture might lead to more stable, scalable and indeed faster training."
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-05-04,13:13:40",Mecha #üì£‚îÉannouncements,Mecha #üì£‚îÉannouncements,"@everyone Happy Star Wars ü§ñ day to you all. As promised here are the long list of updates going on in parallel - 

https://discord.com/channels/1163379146106359858/1368680860496298156

Thank you for reading and being part of this - your support and love keeps us going!

""Rebellions are built on hope"" - Jyn Erso, Rogue One."
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-05-05,13:48:54",Ollama #announcements,Ollama #announcements,"# Ollama 0.6.8

## What's Changed
* Performance improvements for [Qwen 3](https://ollama.com/library/qwen3) MoE models (`30b-a3b` and `235b-a22b`) on NVIDIA and AMD GPUs
* Fixed `GGML_ASSERT(tensor->op == GGML_OP_UNARY) failed` issue caused by conflicting installations
* Fixed a memory leak that occurred when providing images as input
* `ollama show` will now correctly label older vision models such as `llava`
* Reduced out of memory errors by improving worst-case memory estimations
* Fix issue that resulted in a `context canceled` error

**Full Changelog**: https://github.com/ollama/ollama/releases/tag/v0.6.8

@everyone"
d518e59b-69b2-4c57-9e61-22e6cd3af8db,"2025-05-10,06:36:26",Yannic Kilcher #events,Yannic Kilcher #events,"@everyone @meetup 
**Paper Discussion 2025#19**

<t:1746900000:F> until <t:1746907200:t>, @Yannic Kilcher will present `Don't be lazy: CompleteP enables compute-efficient deep transformers` in https://discord.com/channels/714501525455634453/1337720641528401930.

Event:
https://discord.gg/zD7Ju6PE?event=1370755931998130306

If you'd like to present a paper, send a direct message to @zickzack  with a link to the paper and availability information.

**Paper:**
https://arxiv.org/abs/2505.01618

**Abstract:**
We study compute efficiency of LLM training when using different parameterizations, i.e., rules for adjusting model and optimizer hyperparameters (HPs) as model size changes. Some parameterizations fail to transfer optimal base HPs (such as learning rate) across changes in model depth, requiring practitioners to either re-tune these HPs as they scale up (expensive), or accept sub-optimal training when re-tuning is prohibitive. Even when they achieve HP transfer, we develop theory to show parameterizations may still exist in the lazy learning regime where layers learn only features close to their linearization, preventing effective use of depth and nonlinearity. Finally, we identify and adopt the unique parameterization we call CompleteP that achieves both depth-wise HP transfer and non-lazy learning in all layers. CompleteP enables a wider range of model width/depth ratios to remain compute-efficient, unlocking shapes better suited for different hardware settings and operational contexts. Moreover, CompleteP enables 12-34\% compute efficiency improvements over the prior state-of-the-art."
